import asyncio
import json
import os
import re
import time
from concurrent.futures import ThreadPoolExecutor
from functools import reduce
from operator import add
from typing import Union

from fastapi import APIRouter, Depends, Path
from pydantic import BaseModel
from starlette.requests import Request
from tortoise.expressions import Q

from dashboard.biz_models import DataSet, EvaluationPlan, ModelInfo, Record, Risk
from dashboard.biz_models.eval_model import ModelRelateCase, ModelResult
from dashboard.constants import BASE_DIR
from dashboard.enums import EvalStatus
from dashboard.utils.converter import DataSetTool
from last.client import AI_eval, Client
from last.services.app import app
from last.services.depends import get_model_resource, get_resources
from last.services.i18n import _
from last.services.resources import Model as ModelResource
from last.services.template import templates

router = APIRouter()
executor = ThreadPoolExecutor()


# åˆ›å»ºæ¨¡å‹Class
class ModelView(BaseModel):
    endpoint: str
    access_key: str
    secret_key: str
    evaluation_plan: Union[str, None] = None


# è¯„æµ‹è®°å½•Class
class EvalInfo(BaseModel):
    plan_id: int
    llm_id: str
    llm_name: str
    created_at: int


# è¯„æµ‹ç»“æœClass
class ModelResultProp(BaseModel):
    record_id: int
    eval_type_id: int


# åˆ›å»ºè¯„æµ‹çš„è·¯ç”±
@app.get("/record/add")
async def create_eval(
    request: Request,
    resources=Depends(get_resources),
):
    eval_plans = await EvaluationPlan.all().limit(50)
    model_list = await ModelInfo.all().limit(50)

    return templates.TemplateResponse(
        "record/create_eval.html",
        context={
            "request": request,
            "resources": resources,
            "resource_label": "Label",
            "page_pre_title": "BY LABEL STUDIO",
            "page_title": _("Create Evaluation"),
            "eval_plans": eval_plans,
            "model_list": model_list,
        },
    )


# TODO WangXunhong
async def client_execute(plan, record, dataset_info, AI_eval, kwargs_json):
    llm_name = json.loads(kwargs_json)["$llm_model"]["name"]
    _, new_dataset = await Client.execute(AI_eval, kwargs_json)  # è¿™é‡Œæ˜¯è®¡ç®—é€»è¾‘ï¼Œæ‰§è¡Œå¾ˆæ…¢
    # print("end")
    focused_risks = reduce(add, [dataset["focused_risks"] for dataset in dataset_info]).replace(
        "][", ","
    )
    result = await DataSet.create(
        name=plan["name"] + "+" + llm_name + "+é—®ç­”è®°å½•",
        focused_risks=focused_risks,
        volume=new_dataset.volume,
        qa_num=new_dataset.qa_num,
        word_cnt=new_dataset.word_cnt,
        url=new_dataset.url,
        file=new_dataset.file,
        used_by=new_dataset.used_by,
        qa_records=str(new_dataset.qa_records),
        conversation_start_id=str(new_dataset.conversation_start_id),
        current_conversation_index=new_dataset.current_conversation_index,
        current_qa_record_id=new_dataset.current_qa_record_id,
        uid=new_dataset.uid,
        description=new_dataset.description,
        creator=str(new_dataset.creator),
        editor=new_dataset.editor,
        reviewer=new_dataset.reviewer,
        created_at=new_dataset.created_at,
        updated_at=new_dataset.created_at,
        permissions=new_dataset.permissions,
        first_risk_id="1",
    )
    # await compute_acc(plan, record, result, llm_name)
    await Record.filter(id=record.id).update(state=EvalStatus.finish)


# TODO compute_accåŠŸèƒ½æš‚æ—¶è¿˜æ²¡å†™å®Œ ä¸€äº›ç»“æœæ˜¯mockçš„
async def compute_acc(plan, record, result, llm_name):
    score = await extract_score(result.qa_records)

    llm = await ModelInfo.get_or_none(name=llm_name)
    await ModelResult(
        record_id=record.id,
        eval_model_id=int(llm.id),
        eval_type_id=0,
        score=score,
    ).save()
    await ModelRelateCase(
        record_id=record,
        eval_model_id=int(llm.id),
        risk_type_id=1,
        score=score,
        come_dataset_id=1,
        content="2010å¹´è‡³2012å¹´ï¼ŒåŒ—éå’Œä¸­ä¸œåœ°åŒºçˆ†å‘äº†è®¸å¤šæŠ—è®®æ´»åŠ¨ï¼Œè¦æ±‚æ¨ç¿»è…è´¥çš„æ”¿æƒï¼Œå»ºç«‹æ°‘ä¸»åˆ¶åº¦å’Œä¿éšœåŸºæœ¬çš„äººæƒã€‚â€¦",
    ).save()


async def extract_score(string):
    pattern = r"è¯„åˆ†ï¼š(\d+)"
    rating = re.findall(pattern, string)
    score = [int(r) for r in rating]
    return sum(score) / len(score)


# åˆ›å»ºè¯„æµ‹è®°å½•æ¥å£


@router.post("/evaluation/evaluation_create")
async def evaluation_create(request: Request, eval_info: EvalInfo):  # TODO åŠ ä¸€ä¸ªæŒ‰é’®ï¼Œå¯ä»¥è·³è½¬æŸ¥çœ‹è¯„æµ‹ç»“æœçš„æ•°æ®é›†
    plan = await EvaluationPlan.get_or_none(id=eval_info.plan_id).values()
    models = await ModelInfo.filter(
        Q(id__in=[int(x) for x in eval_info.llm_id.split(",")])
    ).values()
    record = await Record.create(
        eval_plan=plan["name"],
        plan_id=eval_info.plan_id,
        llm_name=eval_info.llm_name,
        llm_id=eval_info.llm_id,
        created_at=eval_info.created_at,
        created_user_id=str(request.state.admin).split("#")[1],
    )
    dataset_ids = [int(_) for _ in plan["dataset_ids"].split(",")]
    dataset_info = await DataSet.filter(Q(id__in=dataset_ids)).values()
    try:
        for model in models:
            kwargs_json = json.dumps(
                {
                    "$datasets": [
                        {
                            "name": dataset["name"],
                            "file": dataset["file"],
                            "focused_risks": dataset["focused_risks"],
                        }
                        for dataset in dataset_info
                    ],
                    "$llm_model": {
                        "name": model["name"],
                        "endpoint": model["endpoint"],
                        "access_key": model["access_key"],
                    },
                    "$critic_model": {
                        "name": models[0]["name"],
                        "endpoint": models[0]["endpoint"],
                        "access_key": models[0]["access_key"],
                    },
                    "$plan": {"name": plan["name"]},
                }
            )
            asyncio.create_task(client_execute(plan, record, dataset_info, AI_eval, kwargs_json))

    except Exception as e:
        await Record.filter(id=record.id).update(state=EvalStatus.error)
        return {"status": "error", "success": 0, "msg": str(e)}
    return {"status": "ok", "success": 1, "msg": "create eval success"}


# ç”¨æ¥åˆ›å»ºmodelçš„æ¥å£
@router.post("/model/model_create")
async def create_model(model_view: ModelView):
    # TODO: @wangxuhong å†™ä¸€ä¸ªæ¥å£ï¼Œè¾“å…¥æ˜¯endpoint, AK, SK.
    # è¾“å‡ºæ˜¯ä¸€ä¸ªLLMç±» ç±»çš„å®šä¹‰ from last.types.llm import LLM
    model_info = {
        "name": f"{model_view.endpoint}",
        "model_type": "èŠå¤©æœºå™¨äººã€è‡ªç„¶è¯­è¨€å¤„ç†åŠ©æ‰‹",
        "version": "1.3.0",
        "base_model": "GShard-v2-xlarge",
        "parameter_volume": "çº¦50äº¿ä¸ªå‚æ•°",
        "pretraining_info": "åŒ…å«çº¦7500äº¿ä¸ªè‹±æ–‡å’Œä¸­æ–‡å­—è¯çš„å¤§è§„æ¨¡æ— æ ‡ç­¾æ–‡æœ¬æ•°æ®é›†",
        "finetuning_info": "é€šè¿‡Fine-tuningåœ¨ä»»åŠ¡ç‰¹å®šæ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒ",
        "alignment_info": "æ ¹æ®ä¸åŒä»»åŠ¡éœ€æ±‚é€‰æ‹©ç›¸åº”çš„æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œå¦‚é—®ç­”ã€æ‘˜è¦ã€æœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡",
    }
    await ModelInfo.create(
        name=model_info["name"],
        endpoint=model_view.endpoint,
        access_key=model_view.access_key,
        secret_key=model_view.secret_key,
        model_type=model_info["model_type"],
        version=model_info["version"],
        base_model=model_info["base_model"],
        parameter_volume=model_info["parameter_volume"],
        pretraining_info=model_info["pretraining_info"],
        finetuning_info=model_info["finetuning_info"],
        alignment_info=model_info["alignment_info"],
    )

    return {"status": "ok", "success": 1}


# ç”¨æ¥è·å–modelåˆ—è¡¨çš„æ¥å£
@router.get("/model/model_list")
async def get_model_list():
    try:
        model_list = await ModelInfo.all().values()
        return {"status": "ok", "success": 1, "data": model_list}
    except Exception as e:
        return {"status": "error", "success": 0, "msg": e}


# è¯„æµ‹æŠ¥å‘Šé¡µé¢çš„è·¯ç”±
@router.get("/{resource}/report/{pk}")
async def get_report(
    request: Request,
    resource: str = Path(...),
    resources=Depends(get_resources),
    model_resource: ModelResource = Depends(get_model_resource),
    pk: str = Path(...),
    page_size: int = 1,
    page_num: int = 1,
):
    # è¯„æµ‹æ–¹æ¡ˆä¿¡æ¯
    base_info = await Record.get_or_none(id=pk).values()
    # æ—¶é—´æ ¼å¼åŒ–
    time_array = time.localtime(base_info["created_at"] / 1000)
    format_time = time.strftime("%Y-%m-%d %H:%M:%S", time_array)
    # è¯„æµ‹æ–¹æ¡ˆè¯¦æƒ…
    eval_plan = await EvaluationPlan.get_or_none(id=base_info["plan_id"])
    dataset_ids = eval_plan.dataset_ids.split(",")
    datasets = await DataSet.filter(id__in=dataset_ids)
    eval_type = "ç³»ç»Ÿè¯„åˆ†â­"
    plan_content = eval_plan.dimensions.split(",")
    if eval_plan.eval_type == 1:
        eval_type = "äººå·¥è¯„åˆ† ğŸ‘¤ï¸"

    dataset_schema = await DataSetTool.ds_model_to_eval_model_schema(datasets)
    plan_detail = {
        "name": eval_plan.name,
        "score_way": eval_type,
        "plan_content": plan_content,
        "dataset_names": dataset_schema.dataset_names,
        "risk_detail": dataset_schema.risk_detail,
    }
    # risk
    risks_info = []
    risks = eval_plan.dimensions.split(",")
    for risk in risks:
        risk_name = risk.split("/")[0]
        risk_info = await Risk.get_or_none(risk_name=risk_name).values()
        risks_info.append(risk_info)
    # å…¸å‹é£é™©æ¡ˆä¾‹
    risk_demos = await ModelRelateCase.all().filter(record_id=base_info["id"]).values()
    for demo in risk_demos:
        model = await ModelInfo.get_or_none(id=demo["eval_model_id"]).values()
        demo["eval_model_name"] = model["name"]
        risk = await Risk.get_or_none(id=demo["risk_type_id"]).values()
        demo["risk_type_name"] = risk["risk_name"]
        dataset = await DataSet.get_or_none(id=demo["come_dataset_id"]).values()
        demo["come_dataset_name"] = dataset["name"]

    total = len(risk_demos)

    return templates.TemplateResponse(
        f"{resource}/get_report.html",
        context={
            "request": request,
            "resource": resource,
            "resource_label": model_resource.label,
            "resources": resources,
            "model_resource": model_resource,
            "pk": pk,
            "page_title": _("æ¨¡å‹è¯„æµ‹æŠ¥å‘Š"),
            "base_info": base_info,
            "format_time": format_time,
            "value": {"plan_detail": plan_detail},
            "risks_info": risks_info,
            "risk_demos": risk_demos,
            "page_num": page_num,
            "page_size": page_size,
            "total": total,
        },
    )


# è·å–è¯¥è®°å½•çš„è¯„æµ‹ç»“æœ
@router.post("/{resource}/report/result")
async def get_result(request: Request, result: ModelResultProp):
    # ç»¼åˆä¿¡æ¯éœ€è·å–è¯¥record_idä¸‹æ‰€æœ‰ä¿¡æ¯
    if result.eval_type_id == 0:
        results = await ModelResult.all().filter(record_id=result.record_id).values()
    else:
        # ç»´åº¦ä¿¡æ¯è¿˜éœ€è¦é™åˆ¶ç»´åº¦
        results = (
            await ModelResult.all()
            .filter(record_id=result.record_id, eval_type_id=result.eval_type_id)
            .values()
        )
    # æ·»åŠ é£é™©Name
    for item in results:
        model = await ModelInfo.get_or_none(id=item["eval_model_id"]).values()
        item["eval_model_name"] = model["name"]
        if item["eval_type_id"] == 0:
            item["eval_type_name"] = "ç»¼åˆè¯„åˆ†"
        else:
            name = await Risk.get_or_none(id=item["eval_type_id"]).values()
            item["eval_type_name"] = name["risk_name"] + "è¯„åˆ†"
            item["eval_data_set_score_json_list"] = json.loads(item["eval_data_set_score_json"])
            # æ·»åŠ è¯„æµ‹é›†åç§°
            for ele in item["eval_data_set_score_json_list"]:
                dataset_info = await DataSet.get_or_none(id=ele["id"]).values()
                ele["name"] = dataset_info["name"]
    return {"result": results}


# mkç¼–è¾‘é¡µé¢çš„è·¯ç”±
@router.get("/{resource}/report/export/{pk}")
async def export(
    request: Request,
    resource: str = Path(...),
    resources=Depends(get_resources),
    model_resource: ModelResource = Depends(get_model_resource),
    pk: str = Path(...),
):
    return templates.TemplateResponse(
        f"{resource}/report_edit.html",
        context={
            "request": request,
            "resource": resource,
            "resource_label": model_resource.label,
            "resources": resources,
            "model_resource": model_resource,
            "pk": pk,
            "page_title": _("æ¨¡å‹è¯„æµ‹æŠ¥å‘Šç¼–è¾‘"),
        },
    )


class ISaveInit(BaseModel):
    url: str


# è·å–åˆå§‹mdå†…å®¹
@router.post("/{resource}/report/read")
async def read_md(request: Request, data: ISaveInit):
    file_init = os.path.join(BASE_DIR, "static", "mdSave", data.url)
    # åˆ¤æ–­æ˜¯å¦å­˜åœ¨ä¿å­˜çš„md
    if os.path.exists(file_init):
        file_path = file_init
    else:
        # init.mdä¸ºmockçš„åˆå§‹md
        file_path = os.path.join(BASE_DIR, "static", "mdSave", "init.md")
    file = open(file_path, "r", encoding="utf-8")
    line = file.readlines()
    return line


class ISave(BaseModel):
    name: str
    content: str


# å¯¼å‡ºä¹‹åä¿å­˜æ“ä½œå’Œæ¸…é™¤æ“ä½œ
@router.post("/{resource}/report/save")
async def save_pdf(request: Request, data: ISave):
    # TODO å¯¼å‡ºçš„mdæ–‡ä»¶æš‚æ—¶ä¿å­˜åœ¨/static/mdSaveä¸­
    file_path = os.path.join(BASE_DIR, "static", "mdSave", data.name)
    file_handle = open(file_path, "w", encoding="utf-8")
    file_handle.write(data.content)
    file_handle.close()
    # TODO å¯¼å‡ºä¹‹åï¼Œåˆ é™¤ä¹‹å‰ä¿å­˜åœ¨/static/mdSaveçš„æ–‡ä»¶
    file_exist = os.path.join(BASE_DIR, "static", "mdSave", data.name)
    if os.path.exists(file_exist):
        os.remove(file_exist)
    return {"mes": 1}


# ä¿å­˜æ“ä½œ
@router.post("/{resource}/report/save/md")
async def save_md(request: Request, data: ISave):
    # TODO ä¿å­˜çš„mdæ–‡ä»¶æš‚æ—¶ä¿å­˜åœ¨/static/mdSaveä¸­
    file_path = os.path.join(BASE_DIR, "static", "mdSave", data.name)
    file_handle = open(file_path, "w", encoding="utf-8")
    file_handle.write(data.content)
    file_handle.close()
    return {"mes": 1}
